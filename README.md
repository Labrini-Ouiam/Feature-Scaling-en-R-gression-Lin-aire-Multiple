# 📊 Feature Scaling en Régression Linéaire Multiple

Ce projet explore l'impact de la **normalisation** et de la **mise à l’échelle des variables** sur un modèle de **régression linéaire multiple**. Il s'appuie sur le modèle du **devoir 3** et examine les différences de performances avant et après l’application du **feature scaling**.

---

## 📂 Contenu du projet

📌 `Régression multiple Advertising - Copie.ipynb` : Notebook Jupyter contenant :  
✅ La mise à l’échelle des caractéristiques du modèle  
✅ L'impact du **Feature Scaling** sur les coefficients et les performances  
✅ Une analyse des résultats  

---

## 🚀 Installation et Exécution

### 📌 Prérequis

Assurez-vous d'avoir **Python 3.x** installé ainsi que les bibliothèques suivantes :

```bash
pip install numpy pandas matplotlib scikit-learn
```

### 📌 Exécution

1️⃣ Clonez le repo :  
   ```bash
   git clone https://github.com/Labrini-Ouiam/Feature-Scaling-en-R-gression-Lin-aire-Multiple.git
   ```

2️⃣ Accédez au dossier :  
   ```bash
   cd Feature-Scaling-en-R-gression-Lin-aire-Multiple
   ```

3️⃣ Ouvrez le notebook avec Jupyter :  
   ```bash
   jupyter notebook "Régression multiple Advertising - Copie.ipynb"
   ```

---

## 📊 Analyse et Résultats

Ce projet compare les performances du modèle **avant et après la normalisation** en utilisant :  

📌 **L'erreur quadratique moyenne (MSE)**  
📌 **Le coefficient de détermination (R²)**  
📌 **Les valeurs des coefficients du modèle**  

📌 **Quelles conclusions peut-on tirer ?**  
L'application du feature scaling peut **améliorer la stabilité du modèle**, rendre l’apprentissage plus efficace et réduire les écarts de grandeurs entre les coefficients.

---

## 🔥 Auteur

👤 Développé par **[Labrini Ouiam](https://github.com/Labrini-Ouiam)**  

⭐ **N'hésitez pas à "starrer" le repo si ce projet vous a aidé !** 😊  
